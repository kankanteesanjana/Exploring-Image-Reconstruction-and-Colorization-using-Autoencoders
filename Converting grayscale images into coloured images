import os
import pandas as pd
from torchvision.io import read_image
from torch.utils.data import Dataset
import torch.nn.functional as F
import torch
from skimage.color import rgb2lab, lab2rgb

class EncoderDataset(Dataset):
    def _init_(self, indices, img_dir, transform=None):
        self.img_dir = img_dir
        self.transform = transform
        self.img_indices = indices
        self.gray_path = img_dir+'gray/'
        self.color_path = img_dir+'color/'
    
    def _len_(self):
        return len(self.img_indices)
        
    def _getitem_(self, idx):
        img_name = str(idx)+'.jpg'
        image = read_image(self.gray_path+img_name)
        image = image.unsqueeze(0)
        image = F.interpolate(image,(160,160))
        image = image.squeeze(0)
        image = image.permute(1,2,0)
        image = image.repeat(1,1,3)
        image = image.permute(2,0,1)
        label = read_image(self.color_path+img_name)
        label = label.unsqueeze(0)
        label = F.interpolate(label,(160,160))
        label = label.squeeze(0)
        label = label.permute(1,2,0)
        label = label.permute(2,0,1)
        image = torch.tensor(rgb2lab(image.permute(1,2,0)/255))
        label = torch.tensor(rgb2lab(label.permute(1,2,0)/255))
        
        image = (image + torch.tensor([0, 128, 128])) / torch.tensor([100, 255, 255])
        label = (label + torch.tensor([0, 128, 128])) / torch.tensor([100, 255, 255])
        
        image = image.permute(2,0,1)
        label = label.permute(2,0,1)
        #Use L channel from image to predict a,b channels of label
        image = image[:1,:,:]
        label = label[1:,:,:] 
        return image, label
# Imports
import os

import torch
import torchvision
from torchvision.io import read_image
from torch import nn
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision.datasets import ImageFolder
import torch.optim as optim
import torchvision.transforms as transforms

import matplotlib.pyplot as plt
from PIL import Image
from tqdm.notebook import tqdm
MANUAL_SEED = 42
BATCH_SIZE = 32
SHUFFLE = True
# Create dataset to load the images
class LandscapeDataset(Dataset):
    def _init_(self, transform=None):
        self.dataroot = './landscape Images'
        self.images = os.listdir(f'{self.dataroot}/color')
        self.transform = transform

    def _len_(self):
        return len(self.images)

    def _getitem_(self, idx):
        # Get image Paths
        img_path = self.images[idx]

        # Load the images
        color_img = read_image(f'{self.dataroot}/color/{img_path}') / 255
        gray_img = read_image(f'{self.dataroot}/gray/{img_path}') / 255

        if self.transform:
            color_img = self.transform(color_img)
            gray_img = self.transform(gray_img)

        return color_img, gray_img
transform = transforms.Compose([
    transforms.Resize((150, 150), antialias=False),
])
# Load the dataset
dataset = LandscapeDataset(transform=transform)

# Split the data into train and test data
train_set, test_set = random_split(dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(MANUAL_SEED))

# Load the train and set data
trainloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE)
testloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=SHUFFLE)

